
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></head><body><doctype html="">
    <title>Dance Revolution: Long-Term Dance Generation with Music via Curriculum Learning</title>

    

    <link rel="stylesheet" href="./assets/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="./assets/style.css">
    <link rel="preconnect" href="https://fonts.gstatic.com/">

    
    <meta name="description" content="Project Page for 2D Dance Choreographer">
    <meta name="author" content="Huang Hu">

    <meta property="og:image" content="https://stonyhu.github.io/dancerev/assets/web_preview.png">
    <meta property="og:url" content="https://stonyhu.github.io/dancerev/">
    <meta property="og:type" content="website">
    <meta property="og:title" content="Dance Revolution: Long-Term Dance Generation with Music via Curriculum Learning">
    <meta property="og:video" content="https://www.youtube.com/watch?v=lmE20MEheZ8">
    <meta property="og:description" content="Dance Revolution: Long-Term Dance Generation with Music via Curriculum Learning.">


    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async="" src="./assets/js"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-JM2CPK6QLP');
    </script>

    <style>
        /* greek-ext */
        @font-face {
            font-family: 'Roboto';
            font-style: normal;
            font-weight: 300;
            font-display: swap;
            src: url(https://fonts.gstatic.com/s/roboto/v20/KFOlCnqEu92Fr1MmSU5fCBc4EsA.woff2) format('woff2');
            unicode-range: U+1F00-1FFF;
        }

        /* greek */
        @font-face {
            font-family: 'Roboto';
            font-style: normal;
            font-weight: 300;
            font-display: swap;
            src: url(https://fonts.gstatic.com/s/roboto/v20/KFOlCnqEu92Fr1MmSU5fBxc4EsA.woff2) format('woff2');
            unicode-range: U+0370-03FF;
        }

        /* latin-ext */
        @font-face {
            font-family: 'Roboto';
            font-style: normal;
            font-weight: 300;
            font-display: swap;
            src: url(https://fonts.gstatic.com/s/roboto/v20/KFOlCnqEu92Fr1MmSU5fChc4EsA.woff2) format('woff2');
            unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
        }

        /* latin */
        @font-face {
            font-family: 'Roboto';
            font-style: normal;
            font-weight: 300;
            font-display: swap;
            src: url(https://fonts.gstatic.com/s/roboto/v20/KFOlCnqEu92Fr1MmSU5fBBc4.woff2) format('woff2');
            unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
        }

        /* greek-ext */
        @font-face {
            font-family: 'Roboto';
            font-style: normal;
            font-weight: 400;
            font-display: swap;
            src: url(https://fonts.gstatic.com/s/roboto/v20/KFOmCnqEu92Fr1Mu7mxKOzY.woff2) format('woff2');
            unicode-range: U+1F00-1FFF;
        }

        /* greek */
        @font-face {
            font-family: 'Roboto';
            font-style: normal;
            font-weight: 400;
            font-display: swap;
            src: url(https://fonts.gstatic.com/s/roboto/v20/KFOmCnqEu92Fr1Mu4WxKOzY.woff2) format('woff2');
            unicode-range: U+0370-03FF;
        }

        /* latin-ext */
        @font-face {
            font-family: 'Roboto';
            font-style: normal;
            font-weight: 400;
            font-display: swap;
            src: url(https://fonts.gstatic.com/s/roboto/v20/KFOmCnqEu92Fr1Mu7GxKOzY.woff2) format('woff2');
            unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
        }

        /* latin */
        @font-face {
            font-family: 'Roboto';
            font-style: normal;
            font-weight: 400;
            font-display: swap;
            src: url(https://fonts.gstatic.com/s/roboto/v20/KFOmCnqEu92Fr1Mu4mxK.woff2) format('woff2');
            unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
        }
    </style>

    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    
        <div class="container">
            <div class="row mb-2 mt-4" id="paper-title">
                <h1 class="col-md-12 text-center">
                    Music-Conditioned 2D Dance Choreography
                </h1>
                <h3 class="col-md-12 text-center">
                    Dance Revolution: Long-Term Dance Generation with Music via Curriculum Learning
                </h3>
                <h3 class="col-md-12 text-center">
                </h3>
            </div>

            <div class="row" id="authors">
                <div class="mx-auto text-center">
                    <ul class="list-inline mb-0">
                        <li class="list-inline-item">
                            <a href="">Ruozi Huang*</a><sup>1</sup>

                        </li><li class="list-inline-item">
                            <a href="https://stonyhu.github.io/">Huang Hu*</a><sup>2</sup>

                        </li><li class="list-inline-item">
                            <a href="https://sites.google.com/view/wei-wu-homepage">Wei Wu</a><sup>3</sup>

                        </li><li class="list-inline-item">
                            <a href="http://www.sp.nitech.ac.jp/~swdkei/index.html">Kei Sawada</a><sup>4</sup>

                        </li><li class="list-inline-item">
                            <a href="hhttp://homepage.fudan.edu.cn/zhangmi/en">Mi Zhang</a><sup>1</sup>

                        </li><li class="list-inline-item">
                            <a href="https://scholar.google.com/citations?user=N-wAHCoAAAAJ&hl=en">Daxin Jiang</a><sup>2</sup>
                    </li></ul>
                    <p id="institution">
                        <sup>1</sup>Fudan University &nbsp;&nbsp;&nbsp;&nbsp;
                        <sup>2</sup>Microsoft STCA &nbsp;&nbsp;&nbsp;&nbsp;
                        <sup>3</sup>Meituan &nbsp;&nbsp;&nbsp;&nbsp;
                        <sup>4</sup>Rinna AI
                    </p>
                    <p id="footnote">
                        (<sup>3,4</sup>Work done while at Microsoft STCA)
                    </p>
                </div>
            </div>
            <div class="row mb-2" id="links">
                <div class="mx-auto">
                    <ul class="nav">
                        <li class="nav-item text-center">
                            <a href="https://arxiv.org/pdf/2006.06119.pdf" class="nav-link">
                                <svg style="width:48px;height:48px" viewBox="0 0 24 24">
                                    <path fill="currentColor" d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z"></path>
                                </svg><br>
                                Paper
                            </a>
                        </li>
                        <li class="nav-item text-center">
                            <a href="https://drive.google.com/file/d/1Xc2cpzkGc7Xh8NVa2ehFmapZJZCtBSH0/view" class="nav-link">
                                <svg style="width:48px;height:48px" viewBox="0 0 24 24">
                                    <path fill="currentColor" d="M12,3C7.58,3 4,4.79 4,7C4,9.21 7.58,11 12,11C16.42,11 20,9.21 20,7C20,4.79 16.42,3 12,3M4,9V12C4,14.21 7.58,16 12,16C16.42,16 20,14.21 20,12V9C20,11.21 16.42,13 12,13C7.58,13 4,11.21 4,9M4,14V17C4,19.21 7.58,21 12,21C16.42,21 20,19.21 20,17V14C20,16.21 16.42,18 12,18C7.58,18 4,16.21 4,14Z"></path>
                                </svg><br>
                                Dataset
                            </a>
                        </li>
                        <li class="nav-item text-center">
                            <a href="https://github.com/stonyhu/DanceRevolution" class="nav-link">
                                <svg style="width:48px;height:48px" viewBox="0 0 24 24">
                                    <path fill="currentColor" d="M12,2A10,10 0 0,0 2,12C2,16.42 4.87,20.17 8.84,21.5C9.34,21.58 9.5,21.27 9.5,21C9.5,20.77 9.5,20.14 9.5,19.31C6.73,19.91 6.14,17.97 6.14,17.97C5.68,16.81 5.03,16.5 5.03,16.5C4.12,15.88 5.1,15.9 5.1,15.9C6.1,15.97 6.63,16.93 6.63,16.93C7.5,18.45 8.97,18 9.54,17.76C9.63,17.11 9.89,16.67 10.17,16.42C7.95,16.17 5.62,15.31 5.62,11.5C5.62,10.39 6,9.5 6.65,8.79C6.55,8.54 6.2,7.5 6.75,6.15C6.75,6.15 7.59,5.88 9.5,7.17C10.29,6.95 11.15,6.84 12,6.84C12.85,6.84 13.71,6.95 14.5,7.17C16.41,5.88 17.25,6.15 17.25,6.15C17.8,7.5 17.45,8.54 17.35,8.79C18,9.5 18.38,10.39 18.38,11.5C18.38,15.32 16.04,16.16 13.81,16.41C14.17,16.72 14.5,17.33 14.5,18.26C14.5,19.6 14.5,20.68 14.5,21C14.5,21.27 14.66,21.59 15.17,21.5C19.14,20.16 22,16.42 22,12A10,10 0 0,0 12,2Z"></path>
                                </svg><br>
                                Code
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
            <div class="row mb-3 pt-2">
                <div class="col-md-8 mx-auto">
<!--                     <div class="row no-gutters pb-2">
                        <div class="col-5">
                            <span></span><img src="./assets/teaser-dataset.png" class="img-responsive">
                        </div>
                        <div class="col-2">
                            <span></span><img src="./assets/teaser-model.png" class="img-responsive">
                        </div>
                        <div class="col-5">
                            <img src="./assets/teaser_ani.gif" class="img-responsive">
                            <div class="gif-label bottom-middle">
                                <svg viewBox="0 0 50 7" xmlns="http://www.w3.org/2000/svg">
                                    <text x="5" y="6" font-weight="550">Generated 3D Dance</text>
                                </svg>
                            </div>
                        </div>
                    </div> -->
                    <p class="text-justify">

                        We present a transformer-LSTM hybrid architecture for music-to-dance synthesis and propose a novel curriculum learning strategy, i.e., dynamic auto-condition learning approach, to alleviate the severe exposure bias issue in long-term dance motion sequence generation with music. 
                        Besides, we also release a new <a href="https://drive.google.com/file/d/1Xc2cpzkGc7Xh8NVa2ehFmapZJZCtBSH0/view" target="_blank">2D dance dataset</a>, which contains three-style dance motions (i.e., ballet, hiphop and jp-pop) extracted from the real dance videos available online.
                        Our model generates realistic and smooth dance motions, which are style-consistent and beat-matching with the music from test set and can last one minute under 15 frame per second (FPS).
                        With the help of 3D human pose reconstruction and animation software, this technique can be used to drive various 3D character models, such as the 3D model of  <a href="https://en.wikipedia.org/wiki/Hatsune_Miku" target="_blank">Hatsune Miku</a>, and has the great potential for the virtual advertisement video generation.
                    </p>

                </div>
            </div>
            <div class="row mb-4" id="overview-video">
                <div class="col-md-8 mx-auto grey-container">
                    <h4 class="pb-2"><strong>Paper Overview</strong></h4>
                    <div class="embed-responsive embed-responsive-16by9">
                        <iframe class="embed-responsive-item" src="assets/model_overview.pdf" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                    </div>
                </div>
            </div>
            <div class="row mb-4">
                <div class="col-md-8 mx-auto">
                    <h4><strong>Supplementary Technical Report</strong></h4>
                    <p class="text-justify">
                        We write a <a href="" target="_blank">supplementary technical report</a> for the music-to-dance synthesis task and analysis of Dancing to Music, the primary work published on NeurIPS 2019.
                    </p>

                    <h4><strong>More Dance Generation Samples</strong></h4>
                    <p class="text-justify">
                        Here we show more generated dance samples. Coming soon.
                    </p>
<!--                     <div class="row pt-1 pb-1">
                        <div class="col-md-6">
                            <video class="results" loop="" playsinline="" controls="" width="85%" onloadstart="this.volume=0.1">
                                <source src="assets/gen_results_1.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="col-md-6">
                            <video class="results" loop="" playsinline="" controls="" width="85%" onloadstart="this.volume=0.1">
                                <source src="assets/gen_results_2.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="col-md-6">
                            <video class="results" loop="" playsinline="" controls="" width="85%" onloadstart="this.volume=0.1">
                                <source src="assets/gen_results_3.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="col-md-6">
                            <video class="results" loop="" playsinline="" controls="" width="85%" onloadstart="this.volume=0.1">
                                <source src="assets/gen_results_4.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div> -->
<!--                     <div class="row pt-1 pb-1">
                        <div class="col-md-6">
                            <video class="results" loop="" playsinline="" controls="" width="85%" onloadstart="this.volume=0.1">
                                <source src="assets/gen_results_5.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="col-md-6">
                            <video class="results" loop="" playsinline="" controls="" width="85%" onloadstart="this.volume=0.1">
                                <source src="assets/gen_results_6.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="col-md-6">
                            <video class="results" loop="" playsinline="" controls="" width="85%" onloadstart="this.volume=0.1">
                                <source src="assets/gen_results_7.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="col-md-6">
                            <video class="results" loop="" playsinline="" controls="" width="85%" onloadstart="this.volume=0.1">
                                <source src="assets/gen_results_8.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="col-md-6">
                            <video class="results" loop="" playsinline="" controls="" width="85%" onloadstart="this.volume=0.1">
                                <source src="assets/gen_results_9.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="col-md-6">
                            <video class="results" loop="" playsinline="" controls="" width="85%" onloadstart="this.volume=0.1">
                                <source src="assets/gen_results_10.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div> -->
                </div>
            </div>
<!--             <div class="row mb-4" id="overview-dataset">
                <div class="col-md-8 mx-auto grey-container">
                    <h4 class="pb-2"><strong>AIST++ 3D Dance Motion Dataset</strong></h4>
                    <div class="row pt-1 pb-1">
                        <div class="col-12">
                            <video loop="" playsinline="" controls="" width="85%">
                                <source src="assets/aist_demo.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <br>
                    <p class="text-justify">
                        In order to train our model, we introduce AIST++, a large-scale 3D human dance motion dataset, 
                        which contains a wide variety of 3D motion paired with music
                        It is built upon the 
                        <a href="https://aistdancedb.ongaaccel.jp/" target="_blank">AIST Dance Database</a>,
                        which is an uncalibrated multi-view collection of dance videos.
                        AIST++ dataset is designed to serve as a benchmark for both 
                        motion generation and prediction tasks. It can also potentially benefit 
                        other tasks such as the 2D/3D human pose estimation. To our knowledge, 
                        AIST++ is the largest 3D human dance dataset with 1408 sequences, 30 subjects 
                        and 10 dance genres with basic and advanced choreographies. It also covers over 18k seconds motion
                        data with over 10M corresponding images.
                        For more info about this dataset, please visit 
                        <a href="https://google.github.io/aistplusplus_dataset" target="_blank">the dataset website</a>.
                    </p>
                </div>
            </div> -->
            <div class="row mb-4" id="model">
                <div class="col-md-8 mx-auto grey-container">
                    <h4 class="pb-2"><strong>Model</strong></h4>
                    <p class="text-justify">
                        Coming soon.
                    </p>
                </div>
            </div>
            <div class="row mb-2">
                <div class="col-md-8 mx-auto">
                    <h4 class="mb-3"><strong>Bibtex</strong></h4>
                    <div class="bibtex" style="font-size:13px">@inproceedings{huang2021,
      title={ Dance Revolution: Long-Term Dance Generation with Music via Curriculum Learning},
      author={Ruozi Huang and Huang Hu and Wei Wu and Kei Sawada and Mi Zhang and Daxin Jiang},
      booktitle={International Conference on Learning Representations},
      year={2021}
}</div>
                </div>
            </div>
            <br>
            <div class="row mb-3">
                <div class="col-md-8 mx-auto">
                    <h4><strong>More Thanks</strong></h4>
                    <p class="text-justify">
                        We thank Kazuna Tsuboi, Sayuri Nishida, Shuo Wang, Ke Chen, Chengcheng Liu and Zhan (Cliff) Chen for the generous support, insightful discussion and kind help on this research project.
                        We also thank Kazuna Tsboi for authorizing us the usage of her portrait in synthesized demo video.
                        Besides, many thanks to the authors of <a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose" target="_blank">OpenPose</a>, <a href="https://github.com/NVlabs/Dancing2Music" target="_blank">Dancing2Music</a>, <a href="https://github.com/allenai/longformer" target="_blank">LongFormer</a>, <a href="https://github.com/NVIDIA/vid2vid" target="_blank">Video-to-Video</a> and <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Ci_Optimizing_Network_Structure_for_3D_Human_Pose_Estimation_ICCV_2019_paper.pdf" target="_blank">3D Human Pose Reconstruction</a>.
                        This website is inspired by the template of <a href="https://alexyu.net/pixelnerf/" target="_blank">pixelnerf</a> and special thanks to the author.
                    </p>
                </div>
            </div>
            <div class="row mb-4" id="license">
                <div class="col-md-8 mx-auto grey-container">
                    <br>
                    <p class="text-justify">
                        Dance Revolution: Long-Term Dance Generation with Music via Curriculum Learning assets are Copyright 2021 @ Microsoft Corporation, licensed under the MIT license.
                    </p>
                </div>
            </div>
            
        </div> <!-- container -->
    

</doctype>
</body></html>
